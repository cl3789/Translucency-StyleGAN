{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.decomposition import PCA, FastICA, DictionaryLearning, MiniBatchDictionaryLearning\n",
    "from skimage.transform import pyramid_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadImgDir:\n",
    "    def __init__(self,\n",
    "                 path_dir: str,\n",
    "                 flag_crop: bool = False,\n",
    "                 size_crop: int = 256,\n",
    "                 flag_resize: bool = False,\n",
    "                 scale_resize: float = 0.25):\n",
    "        self.fname_list_img = glob.glob(path_dir)\n",
    "        self.fname_list_img.sort()\n",
    "        self.num_img = len(self.fname_list_img)\n",
    "        self.flag_crop = flag_crop\n",
    "        self.size_crop = size_crop\n",
    "        self.flag_resize = flag_resize\n",
    "        self.scale_resize = scale_resize\n",
    "        self.imgs = []\n",
    "        self.imgs_float = []\n",
    "        self.size_img = []\n",
    "        self.labels = []\n",
    "        print('num of images is ' + str(self.num_img))\n",
    "        #self.read_imgs_fromdir()\n",
    "\n",
    "    def read_imgs_fromdir(self):\n",
    "\n",
    "        for i_list in range(self.num_img):\n",
    "            print(self.fname_list_img[i_list])\n",
    "            img = Image.open(self.fname_list_img[i_list])\n",
    "\n",
    "            if self.flag_resize:\n",
    "                width, height = img.size\n",
    "                img = img.resize((int(width*self.scale_resize), int(height*self.scale_resize)))\n",
    "\n",
    "            self.imgs.append(img)\n",
    "            self.labels.append(os.path.basename(self.fname_list_img[i_list]))\n",
    "\n",
    "\n",
    "\n",
    "    def cal_mean_std(self):\n",
    "\n",
    "        mean_img = []\n",
    "        std_img = []\n",
    "        if len(img.shape) == 2:\n",
    "            mean_img.append(np.mean(img))\n",
    "            std_img.append(np.std(img))\n",
    "        else:\n",
    "            mean_img.append(np.mean(img, 2))\n",
    "            std_img.append(np.std(img, 2))\n",
    "\n",
    "    def divide_imgs_col(self, num_divide: int = 4, flag_dif: bool = True, path_save_dir: str =''):\n",
    "        # this divide each image in the horizontal direction with the number of num_divide.\n",
    "        # this function will update self.imgs and self.num_img\n",
    "        # for a specific project I put a function to take a difference from the first image in each cutting.\n",
    "        # imgs = []\n",
    "        labels = []\n",
    "        \n",
    "        \n",
    "        ## Only process the Opaque-translucent pairs\n",
    "        for label in self.fname_list_img:\n",
    "            if label.partition(\"_\")[2][0] == \"O\" and label.partition(\"_to_\")[2][0] == \"T\": ## I added this line\n",
    "                img = Image.open(label)\n",
    "                if self.flag_resize:\n",
    "                    width, height = img.size\n",
    "                    img = img.resize((int(width*self.scale_resize), int(height*self.scale_resize)))\n",
    "                width, height = img.size\n",
    "                cut_shape = int(width/num_divide)\n",
    "                img = np.array(img)\n",
    "                img = img.astype('float')\n",
    "                for i in range(num_divide):\n",
    "                    img_div = copy.deepcopy(img[:, i * cut_shape: i * cut_shape + cut_shape, :])\n",
    "                    if flag_dif:\n",
    "                        if i == 0:\n",
    "                            img_1 = copy.deepcopy(img_div)\n",
    "                        else:\n",
    "                            img_tmp = img_div - img_1 + 128\n",
    "                            self.imgs_float.append(img_tmp)\n",
    "                            print('min: ' + str(np.min(img_tmp)) + 'max:' + str(np.max(img_tmp)))\n",
    "                            img_tmp[np.where(img_tmp < 0)] = 0\n",
    "                            img_tmp[np.where(img_tmp > 255)] = 255\n",
    "                            img_tmp = img_tmp.astype('uint8')\n",
    "                            img_tmp = Image.fromarray(img_tmp)\n",
    "                            #imgs.append(img_tmp)\n",
    "                            label_body, ext  = os.path.splitext(os.path.basename(label))\n",
    "                            labels.append(label_body + '_' + str(i) + ext)\n",
    "                            self.save_img(path_save_dir, img_tmp, label_body + '_' + str(i) + ext)\n",
    "                    else:\n",
    "                        img_tmp = img_tmp.astype('uint8')\n",
    "                        img_tmp = Image.fromarray(img_tmp)\n",
    "                        #imgs.append(img_div)\n",
    "                        label_body, ext = os.path.splitext(os.path.basename(label))\n",
    "                        labels.append(label_body + '_' + str(i) + ext)\n",
    "                        self.save_img(path_save_dir, img_tmp, label_body + '_' + str(i) + ext)\n",
    "\n",
    "        #self.imgs = imgs\n",
    "        self.size_img = np.array(img_tmp).shape\n",
    "        self.labels = labels\n",
    "        self.num_img = self.num_img * num_divide\n",
    "\n",
    "    def save_img(self, path_save_dir, img, label):\n",
    "        label, ext = os.path.splitext(label)\n",
    "        img.save(path_save_dir+label+'.png', format='PNG')\n",
    "\n",
    "    def save_imgs(self, path_save_dir):\n",
    "        for i, img in enumerate(self.imgs):\n",
    "            label, ext = os.path.splitext(self.labels[i])\n",
    "            img.save(path_save_dir+label+'.png', format='PNG')\n",
    "\n",
    "    def crop_img(self, img, size_crop):\n",
    "        h_size_crop = int(size_crop/2)\n",
    "        size_img = img.shape\n",
    "        pos_center_x = int(size_img[1]/2)\n",
    "        pos_center_y = int(size_img[0]/2)\n",
    "        img = img[pos_center_y-h_size_crop:pos_center_y+h_size_crop,\n",
    "                            pos_center_x-h_size_crop:pos_center_x+h_size_crop,:]\n",
    "        return img\n",
    "\n",
    "    def open_img(self, path, label):\n",
    "        label_body, ext = os.path.splitext(label)\n",
    "        return Image.open(path + label_body + '.png')\n",
    "\n",
    "    def crop_imgs(self, size_crop, path, path_save):\n",
    "        h_size_crop = int(size_crop/2)\n",
    "        pos_center_x = int(self.size_img[1]/2)\n",
    "        pos_center_y = int(self.size_img[0]/2)\n",
    "        for label in self.labels:\n",
    "            print(label)\n",
    "            img = self.open_img(path, label)\n",
    "            img = img.crop((pos_center_x-h_size_crop,pos_center_y-h_size_crop,\n",
    "                     pos_center_x+h_size_crop,pos_center_y+h_size_crop))\n",
    "            self.save_img(path_save, img, label)\n",
    "\n",
    "    def cut_imgs(self, size_cut, path_save):\n",
    "\n",
    "        imgs_cut = []\n",
    "        num_height = int(list_imgs.size_img[0]/size_cut)\n",
    "        num_width = int(list_imgs.size_img[1] / size_cut)\n",
    "        count = 0\n",
    "        for img in self.imgs_float:\n",
    "            for h in range(num_height):\n",
    "                for w in range(num_width):\n",
    "                    count += 1\n",
    "                    tmp = img[h*size_cut:h*size_cut+size_cut,\n",
    "                            w*size_cut:w*size_cut+size_cut, :]\n",
    "                    imgs_cut.append(tmp)\n",
    "                    tmp = tmp.astype('uint8')\n",
    "                    tmp = Image.fromarray(tmp)\n",
    "                    self.save_img(path_save, tmp, str(count))\n",
    "        self.imgs_float = imgs_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_roi(imgs, size_cut, num_patches_per_img, state):\n",
    "    \n",
    "    print(\"shape imgs:\",imgs.shape)\n",
    "\n",
    "    roi = []\n",
    "    np.random.seed(state)\n",
    "    for ind_img in range(imgs.shape[0]):\n",
    "        for ind_patches in range(num_patches_per_img):\n",
    "            x_start = np.random.randint(0, imgs.shape[2] - size_cut - 1)\n",
    "            y_start = np.random.randint(0, imgs.shape[1] - size_cut - 1)\n",
    "            #print(x_start, y_start)\n",
    "            roi.append(np.reshape(imgs[ind_img, y_start: y_start + size_cut, \n",
    "                                  x_start: x_start + size_cut, :],\n",
    "                                  [size_cut, size_cut, 3]))\n",
    "    return np.array(roi)\n",
    "\n",
    "def cal_norm(imgs):\n",
    "    mean_imgs = np.mean(imgs)\n",
    "    std_imgs = np.std(imgs)\n",
    "    imgs_norm = (imgs - mean_imgs)/std_imgs\n",
    "\n",
    "    return imgs_norm, mean_imgs, std_imgs\n",
    "\n",
    "def cal_ica(imgs, num_components):\n",
    "    ica = FastICA(num_components, random_state = 42, tol = 0.1)\n",
    "    ica.fit(imgs)\n",
    "\n",
    "    return ica\n",
    "\n",
    "def cal_dictionary(imgs, num_components):\n",
    "    dict_learner = DictionaryLearning(n_components=num_components, transform_algorithm='lasso_lars', n_jobs=-1)\n",
    "    dict_learner.fit(imgs)\n",
    "\n",
    "    return dict_learner\n",
    "\n",
    "\n",
    "def cal_dictionary_minibatch(imgs, num_components):\n",
    "    minidict_learner = MiniBatchDictionaryLearning(n_components=num_components, transform_algorithm='lasso_lars',\n",
    "                                                  batch_size=10,n_jobs=-1)\n",
    "    minidict_learner.fit(imgs)\n",
    "\n",
    "    return minidict_learner\n",
    "\n",
    "def cal_sequential_sample(path):\n",
    "    with open(path, mode='rb') as f:\n",
    "        imgs = pickle.load(f)\n",
    "\n",
    "    imgs = np.array(imgs)\n",
    "    imgs = imgs[0:1000, :, :, :]\n",
    "    size_imgs = imgs.shape\n",
    "\n",
    "def make_panels(model, num_components, size_imgs, scale_contrast = 2):\n",
    "    kernels = np.reshape(model.components_, [num_components, size_imgs[1], size_imgs[2], size_imgs[3]])\n",
    "    print(\"before transpose:\",kernels.shape)\n",
    "    kernels = kernels - np.min(kernels)\n",
    "    kernels = kernels / np.max(kernels)\n",
    "    kernels = scale_contrast*128*(kernels - np.mean(kernels)) + 128\n",
    "    kernels[np.where(kernels<0)] = 0\n",
    "    kernels[np.where(kernels>255)] = 255\n",
    "    kernels = kernels.astype('uint8')\n",
    "    kernels = kernels.transpose(0, 3, 1, 2)\n",
    "    print(\"after transpose:\",kernels.shape)\n",
    "    kernels = torch.from_numpy(kernels)\n",
    "    \n",
    "    num_row = 8\n",
    "    kernels = torchvision.utils.make_grid(kernels, nrow=num_row)\n",
    "    kernels = kernels.to('cpu').detach().numpy().transpose(1, 2, 0).copy()\n",
    "\n",
    "    return kernels\n",
    "\n",
    "def save_kernels(model, num_components, size_imgs):\n",
    "    kernels = np.reshape(model.components_, [num_components, size_imgs[1], size_imgs[2], size_imgs[3]])\n",
    "    kernels = kernels.transpose(0, 3, 1, 2)\n",
    "    kernels = torch.from_numpy(kernels)\n",
    "    return kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(imgs, size_cut, num_patches_per_img):\n",
    "    imgs = sample_roi(imgs, size_cut, num_patches_per_img,)\n",
    "    size_imgs = imgs.shape\n",
    "    #reshape\n",
    "    imgs = np.reshape(imgs,[size_imgs[0], size_imgs[1]*size_imgs[2]*size_imgs[3]])\n",
    "    print(imgs.shape)\n",
    "    #normalize\n",
    "    imgs_norm, mean_imgs, std_imgs = cal_norm(imgs)\n",
    "    \n",
    "    return imgs_norm\n",
    "\n",
    "def get_norm_patches(imgs, size_cut, type_model, num_patches_per_img, panel_save, kernel_save_path, num_components = 100, rand_state=42):\n",
    "    imgs = sample_roi(imgs, size_cut, num_patches_per_img, rand_state)\n",
    "    size_imgs = imgs.shape\n",
    "    #reshape\n",
    "    imgs = np.reshape(imgs,[size_imgs[0], size_imgs[1]*size_imgs[2]*size_imgs[3]])\n",
    "    #normalize\n",
    "    imgs_norm, mean_imgs, std_imgs = cal_norm(imgs)\n",
    "    \n",
    "    print(type_model)\n",
    "    \n",
    "    if type_model=='ica':\n",
    "        model = cal_ica(imgs_norm, num_components)\n",
    "    elif type_model=='minidict':\n",
    "        model = cal_dictionary_minibatch(imgs_norm, num_components)\n",
    "    elif type_model == 'sparse':\n",
    "        model = cal_dictionary(imgs_norm, num_components)\n",
    "        \n",
    "    scale_contrast = 6\n",
    "    panels = make_panels(model, num_components, size_imgs, scale_contrast)\n",
    "    \n",
    "    kernels = save_kernels(model, num_components, size_imgs)\n",
    "\n",
    "    panels = panels.astype('uint8')\n",
    "    panels = Image.fromarray(panels)\n",
    "    panels.save(panel_save)\n",
    "    \n",
    "    ## Save Sparse coding kernels\n",
    "    kernels_save = copy.deepcopy(kernels)\n",
    "    np.save(kernel_save_path,kernels_save)\n",
    "    \n",
    "\n",
    "def get_imgs(img_path):\n",
    "    ## Get a list of images from directory\n",
    "    \n",
    "    img_names = glob.glob(img_path)\n",
    "\n",
    "    imgs = []\n",
    "    for label in img_names:\n",
    "        print(label)\n",
    "        img = Image.open(label)\n",
    "        img_norm = trans_for_conv(img)\n",
    "        imgs.append(img_norm)\n",
    "        \n",
    "    return imgs, img_names\n",
    "\n",
    "def show_kernel(kernels):\n",
    "    scale_contrast = 1\n",
    "    kernels = kernels - np.min(kernels)\n",
    "    kernels = kernels / np.max(kernels)\n",
    "    kernels = scale_contrast*128*(kernels - np.mean(kernels)) + 128\n",
    "    kernels[np.where(kernels<0)] = 0\n",
    "    kernels[np.where(kernels>255)] = 255\n",
    "    kernels = kernels.astype('uint8')\n",
    "    \n",
    "    return kernels\n",
    "\n",
    "\n",
    "def conv_3d(img, kernel, scalecontrast=2):\n",
    "    ## Apply 3D convolution of a learned kernel to the image\n",
    "    \n",
    "    H, W = kernel.shape[1], kernel.shape[2] ## H, W = 24, 24\n",
    "    kernel = torch.tensor(kernel, dtype=torch.float32).unsqueeze(0).expand(1, 1, 3, H, W)\n",
    "    \n",
    "    out = F.conv3d(img, kernel, stride=1, padding=\"same\", groups=1)\n",
    "    out = out.squeeze().numpy().transpose(1, 2, 0)\n",
    "   \n",
    "    out = scalecontrast*128*(out - np.mean(out)) + 128\n",
    "    out[np.where(out<0)] = 0\n",
    "    out[np.where(out>255)] = 255\n",
    "    out = out.astype('uint8')\n",
    "\n",
    "    feature_map = Image.fromarray(out, 'RGB')\n",
    "    \n",
    "    return feature_map\n",
    "\n",
    "def save_kernels_conv(img, kernels,scale_constrast, save_path=None):\n",
    "    feature_maps = []\n",
    "    for i in range(kernels.shape[0]):\n",
    "        feature_map_i = plot_feature(img, kernels,i, scale_constrast)\n",
    "        feature_maps.append(feature_map_i)\n",
    "    \n",
    "    return feature_maps\n",
    "\n",
    "def plot_selected_kernels_conv(img, kernels, kernel_num, scale_constrast):\n",
    "    \n",
    "    feature_maps = []\n",
    "    for i in kernel_num:\n",
    "        print(\"Kernel:\", i)\n",
    "        kernel_i =  show_kernel(kernels[i])\n",
    "        plt.imshow(kernel_i.transpose(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        feature_map_i = plot_feature(img, kernels, i, scale_constrast)\n",
    "        plt.imshow(feature_map_i)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "def plot_feature(img, kernel,kernel_id, scale_constrast):\n",
    "    kernel = kernel[kernel_id]\n",
    "    feature_map = conv_3d(img,kernel,scale_constrast)\n",
    "    \n",
    "    return feature_map\n",
    "\n",
    "\n",
    "def plot_kernels(kernel_img_list, figname):\n",
    "    n_row = 8\n",
    "    n_col = 8\n",
    "    fig, axs = plt.subplots(figsize=(20, 20))\n",
    "    axs.set_axis_off()\n",
    "    \n",
    "    grid = ImageGrid(fig, 111, \n",
    "                     nrows_ncols=(n_row, n_col),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes\n",
    "                     share_all=True,\n",
    "                     )\n",
    "\n",
    "    for i in range(len(kernel_img_list)):\n",
    "        grid[i].axis('off')\n",
    "        grid[i].imshow(kernel_img_list[i])\n",
    "        \n",
    "\n",
    "    plt.show()\n",
    "    #fig.axis('off')\n",
    "\n",
    "    fig.savefig(figname)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532e108",
   "metadata": {},
   "source": [
    "## Process middle layer style mix images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a510dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resize images to 512 x 512\n",
    "scale_resize = 0.5\n",
    "width, height = 1024, 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9145ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_high_res32 = glob.glob('../middle_layer_mix_trbg_top40/res32_trgb_high/*.jpg') \n",
    "middle_layer_high_res32 = np.array([np.array(Image.open(fname).resize((int(width*scale_resize), int(height*scale_resize)))) for fname in filelist_high_res32])\n",
    "middle_layer_high_res32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_high_res64 = glob.glob('../middle_layer_mix_trbg_top40/res64_trgb_high/*.jpg') \n",
    "middle_layer_high_res64 = np.array([np.array(Image.open(fname).resize((int(width*scale_resize), int(height*scale_resize)))) for fname in filelist_high_res64])\n",
    "middle_layer_high_res64.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f789dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random sample from 3160 image\n",
    "#imgs_high = middle_layer_high[0:3160, :, :, :]\n",
    "imgs_high_res64 = middle_layer_high_res64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ef99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_high_res16 = middle_layer_high_res16\n",
    "n = 1000  # for 2 random indices\n",
    "index = np.random.choice(middle_layer_high_res16.shape[0], n, replace=False)  \n",
    "imgs_high_res16 = middle_layer_high_res16[index]\n",
    "imgs_high_res16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f82027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs_high_res64[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdef3f",
   "metadata": {},
   "source": [
    "# Run ICA (Figure 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572dc52c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## ICA for 32 res trgb (early-layers)\n",
    "patch_size = 48 ## Size of image patch\n",
    "seed = 100      ## Random seed for ICA\n",
    "\n",
    "high_trans_panel_fname = '../feature_kernels/patch24_res32_high_trans_ica_random_state' + str(seed) +'.png'\n",
    "high_trans_kernel_fname = '../feature_kernels/patch24_res32_high_trans_ica_random_state' + str(seed) + '.npy'\n",
    "get_norm_patches(imgs_high, size_cut=patch_size,type_model=\"ica\",num_patches_per_img=10, panel_save=high_trans_panel_fname, kernel_save_path=high_trans_kernel_fname, num_components = 160, rand_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aad3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ICA for 64 res trgb (middle-layers)\n",
    "\n",
    "patch_size = 24\n",
    "seed = 100\n",
    "num_comp = 64\n",
    "\n",
    "high_trans_panel_fname = '../feature_kernels/patch24_res64_high_trans_ica_random_state' + str(seed) + \"_\"+ str(num_comp)+'component.png'\n",
    "high_trans_kernel_fname = '../feature_kernels/patch24_res64_high_trans_ica_random_state' + str(seed) + \"_\" + str(num_comp) + 'component.npy'\n",
    "get_norm_patches(imgs_high_res64, size_cut=patch_size,type_model=\"ica\",num_patches_per_img=10, panel_save=high_trans_panel_fname, kernel_save_path=high_trans_kernel_fname, num_components = num_comp, rand_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8060e49",
   "metadata": {},
   "source": [
    "## Plot convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45baad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_for_conv = transforms.Compose([\n",
    "        transforms.Resize(512),                 \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9278c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_kernels_high_64res = np.load(\"../feature_kernels/patch24_res64_high_trans_ica_random_state100_64component.npy\")\n",
    "ica_kernels_high_64res.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46255bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the lists of real and encoded images\n",
    "path_to_generated_img = '../example-soaps/*'\n",
    "\n",
    "generated_imgs,_ = get_imgs(path_to_generated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1eecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = generated_imgs[3]\n",
    "plt.imshow(np.array(test_img).transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "\n",
    "test_img = test_img.expand(1,1,3,512,512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_save_path = '../feature_kernels/ica_roundgreen_example_high_res64_64comp'\n",
    "\n",
    "scale_contrast = 5\n",
    "ica_kernels_res64_conv = save_kernels_conv(test_img, ica_kernels_high_64res, scale_contrast)\n",
    "plot_kernels(ica_kernels_res64_conv, ica_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ccb5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_selected_kernels_conv(test_img, ica_kernels_high_64res, [19, 24, 52, 63, 45], 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
