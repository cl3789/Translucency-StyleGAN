{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd2a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch, re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, kendalltau, spearmanr\n",
    "\n",
    "import altair as alt\n",
    "import base64, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_demos(data,data_type,num_row_to_drop):\n",
    "    data = data.drop(range(0,num_row_to_drop))\n",
    "    if data_type == \"real-fake-judgement\":\n",
    "        data['ground_truth'] = data['ground_truth'].astype(int)\n",
    "        data = data.replace([0,1],[\"fake\", \"real\"])\n",
    "    elif data_type == \"SAR\":\n",
    "        data[\"ground_truth\"] = data[\"ground_truth\"].replace([\"0\",\"1\"],[\"fake\", \"real\"])\n",
    "    return data\n",
    "\n",
    "def process_individual_SAR(file_path, file_name, column_to_read, rows_to_skip):\n",
    "    participant_file_path = os.path.join(file_path, file_name)\n",
    "    participant_data = pd.read_csv(participant_file_path, usecols = column_to_read)\n",
    "    \n",
    "    participant_data = drop_demos(participant_data, \"SAR\", rows_to_skip)\n",
    "    return participant_data\n",
    "\n",
    "def process_all_people_SAR(file_path, attribute_name):\n",
    "    files = list(filter(lambda f: os.path.isfile(os.path.join(file_path,f)), os.listdir(file_path)))\n",
    "\n",
    "    df_stat = pd.DataFrame()\n",
    "    \n",
    "    trial_num_path = os.path.join(file_path, files[0])\n",
    "    #print(trial_num_path)\n",
    "    \n",
    "    image_info = [\"Trial_num\",\"image_name\", \"image_path\",\"ground_truth\"]\n",
    "    aggregate = pd.read_csv(trial_num_path, usecols = image_info)\n",
    "    aggregate = drop_demos(aggregate, \"SAR\", 5)\n",
    "    \n",
    "    use_response = [\"Trial_num\",\"image_name\",\"image_path\", \"ground_truth\", attribute_name]\n",
    "    \n",
    "    for person_data in files:\n",
    "        if fnmatch.fnmatch(person_data, '*.csv'):\n",
    "            person_result = process_individual_SAR(file_path, person_data, use_response, 5)\n",
    "            #Normalize to 0-1 range\n",
    "            person_result[attribute_name] = (person_result[attribute_name]-person_result[attribute_name].min())/(person_result[attribute_name].max()-person_result[attribute_name].min())\n",
    "            aggregate = pd.concat([aggregate, person_result[attribute_name]], axis=1)\n",
    "            all_res_name = attribute_name + \"_all\"\n",
    "            aggregate[all_res_name] =  aggregate[aggregate.columns[4]].values.tolist()\n",
    "            aggregate[\"mean_rating\"] = aggregate[all_res_name].apply(np.mean)\n",
    "            \n",
    "    return aggregate\n",
    "\n",
    "def combine_attributes():\n",
    "    ## Merge All Attribute Mean ratings\n",
    "    all_attribute_wide = pd.DataFrame({'image_name':translucency_score['image_name'],\n",
    "                                    'image_path':translucency_score['image_path'],\n",
    "                                  'ground_truth':translucency_score['ground_truth'],\n",
    "                                  'translucency_mean':translucency_score[\"mean_rating\"],\n",
    "                                  'see_throughness_mean':seethroughness_score[\"mean_rating\"],\n",
    "                                  'glow_mean':glow_score[\"mean_rating\"]}) \n",
    "\n",
    "    all_attribute_long = pd.melt(all_attribute_wide, id_vars=['image_name','image_path','ground_truth'],\n",
    "                            var_name='attribute', value_name='mean_rating',\n",
    "            value_vars=['translucency_mean', 'see_throughness_mean','glow_mean'])\n",
    "    \n",
    "    return all_attribute_wide, all_attribute_long\n",
    "\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    ## Correlation plots\n",
    "    r, p = stats.spearmanr(x, y)\n",
    "    ax = plt.gca()\n",
    "    # count how many annotations are already present\n",
    "    n = len([c for c in ax.get_children() if \n",
    "                  isinstance(c, matplotlib.text.Annotation)])\n",
    "    #  make positions for every label by hand\n",
    "    pos = (.1, .9) if kws['label'] == 'real' else (.1,.85)\n",
    "\n",
    "    ax.annotate(\"{}: rho = {:.3f}, p = {:.08f}\".format(kws['label'],r, p),fontsize = 20,\n",
    "                xy=pos, xycoords=ax.transAxes)\n",
    "    \n",
    "def my_hist(x, label, color):\n",
    "    ax0 = plt.gca()\n",
    "    ax = ax0.twinx()\n",
    "    \n",
    "    sns.despine(ax=ax, left=True, top=True, right=False)\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.set_ylabel('Counts')\n",
    "    \n",
    "    ax.hist(x, label=label, color=color)\n",
    "\n",
    "    \n",
    "def annotate_scatter(data, **kws):\n",
    "    x = data['mean_rating']\n",
    "    y = data['dist_norm']\n",
    "    r, p = stats.pearsonr(x, y)\n",
    "#     r, p = stats.spearmanr(x, y)\n",
    "    r, p = round(r,2), round(p,3)\n",
    "    ax = plt.gca()\n",
    "    ax.text(.1, .9, f\"r_hc = {r}, p = {p}\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "def plot_svm_predict(file_name):\n",
    "    #print(os.path.basename(file_name))\n",
    "    svm_prediction = pd.read_csv(file_name)\n",
    "    svm_vs_human = all_attributes_wide[all_attributes_wide[\"ground_truth\"] == \"fake\"].merge(svm_prediction, how='left', on='image_name')\n",
    "    \n",
    "    svm_vs_human[\"dist_norm\"] = (svm_vs_human[\"distance_bound\"]-svm_vs_human[\"distance_bound\"].min())/(svm_vs_human[\"distance_bound\"].max()-svm_vs_human[\"distance_bound\"].min())\n",
    "    print(svm_vs_human)\n",
    "    r_tran, p_tran = stats.pearsonr(svm_vs_human['translucency_mean'], svm_vs_human[\"dist_norm\"])  \n",
    "    r_see, p_see = stats.pearsonr(svm_vs_human['see_throughness_mean'], svm_vs_human[\"dist_norm\"])  \n",
    "    r_glow, p_glow = stats.pearsonr(svm_vs_human['glow_mean'], svm_vs_human[\"dist_norm\"])  \n",
    "    \n",
    "    print(\"Translucency r:\",r_tran, p_tran)\n",
    "    print(\"See-through r:\",r_see, p_see)\n",
    "    print(\"Glow r:\",r_glow, p_glow)\n",
    "\n",
    "\n",
    "    \n",
    "    svm_vs_human_long =  pd.melt(svm_vs_human, id_vars=['image_name','image_path','ground_truth','distance_bound','dist_norm','predicted'],\n",
    "                                var_name='attribute', value_name='mean_rating',\n",
    "                value_vars=['translucency_mean', 'see_throughness_mean','glow_mean'])\n",
    "    \n",
    "    svm_vs_human_long.to_csv(\"svm_vs_human_long_layer9.csv\")\n",
    "    \n",
    "    file_name = os.path.basename(file_name)\n",
    "    sns.color_palette(\"rocket\", as_cmap=True)\n",
    "    g = sns.FacetGrid(svm_vs_human_long,\"attribute\", margin_titles=False, hue = \"attribute\", hue_order = [\"see_throughness_mean\",\"glow_mean\", \"translucency_mean\"],\n",
    "                      hue_kws=dict(marker=[\"X\", \"s\", \"o\"]), height=3, aspect=1.2,\n",
    "                     palette = \"deep\")\n",
    "\n",
    "    g.map_dataframe(sns.scatterplot, x=\"dist_norm\", y=\"mean_rating\", s = 70, alpha = 1)\n",
    "    #g.map_dataframe(annotate_scatter)\n",
    "    g.set(ylabel='Mean attribute rating', ylim=(0, 1))\n",
    "    g.set_titles(' ', ' ', ' ')\n",
    "    \n",
    "    plt.xticks([0, 0.5, 1])\n",
    "    plt.yticks([0, 0.5, 1])\n",
    "    g.set(xlabel=None, ylabel=None, xticklabels=[], yticklabels=[])\n",
    "    #g.fig.suptitle(file_name)\n",
    "\n",
    "    return r_tran, r_see, r_glow, p_tran, p_see, p_glow\n",
    "\n",
    "    \n",
    "def plot_r_trend(file_path):\n",
    "    layer_names, r_trans_layers, r_see_layers, r_glow_layers, p_tran_layers, p_see_layers, p_glow_layers= [],[],[],[],[],[],[]\n",
    "    for i in range(18):\n",
    "        print(\"Layer:\", i)\n",
    "        layer_name = str(i)\n",
    "        path = file_path + str(i) + \".csv\"\n",
    "        r_tran, r_see, r_glow, p_tran, p_see, p_glow = plot_svm_predict(path)\n",
    "\n",
    "        layer_names.append(layer_name)\n",
    "        r_trans_layers.append(np.abs(r_tran))\n",
    "        r_see_layers.append(np.abs(r_see))\n",
    "        r_glow_layers.append(np.abs(r_glow))\n",
    "        p_tran_layers.append(p_tran) \n",
    "        p_see_layers.append(p_see)\n",
    "        p_glow_layers.append(p_glow)\n",
    "\n",
    "    r_table = pd.DataFrame({'layer_name':layer_names,\n",
    "                            'translucent': r_trans_layers,\n",
    "                            'see-throughness':r_see_layers,\n",
    "                            'glow':r_glow_layers,\n",
    "                            'tran-p':p_tran_layers,\n",
    "                            'see-p':p_see_layers,\n",
    "                            'glow-p':p_glow_layers\n",
    "                            })\n",
    "\n",
    "    return r_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be412cc",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data\n",
    "SAR_folder_path = \"data/Experiment2\"\n",
    "\n",
    "seethroughness_score = process_all_people_SAR(SAR_folder_path, \"seethroughness_score.response\")\n",
    "translucency_score = process_all_people_SAR(SAR_folder_path, \"translucency_score.response\")\n",
    "glow_score = process_all_people_SAR(SAR_folder_path, \"glow_score.response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65efe71a",
   "metadata": {},
   "source": [
    "# Plot material attribute ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf6b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define color palette for data of real and generated images \n",
    "\n",
    "real_fake_color_palette = dict(real=\"#bdbdbd\", fake=\"#2ca02c\")\n",
    "\n",
    "real_fake_hue_order = [\"fake\",\"real\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf80af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(df, title):\n",
    "    plot = sns.histplot(data=df, x=\"mean_rating\", hue=\"ground_truth\",binwidth = 0.2,stat=\"percent\", alpha=0.7,\n",
    "                                 hue_order=real_fake_hue_order,edgecolor= \"white\",linewidth=1,\n",
    "                                 shrink=1,common_norm=False,\n",
    "                                 palette=real_fake_color_palette, legend=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    plot.set(xticks=np.arange(0,1.2,0.2), yticks=np.arange(0,61,20))\n",
    "\n",
    "\n",
    "    sns.move_legend(plot, \"upper left\", bbox_to_anchor=(1, 1), title='Groun truth')\n",
    "    sns.set_context(context='poster', font_scale=0.8)\n",
    "    sns.despine(offset=10, left=False, right = True)\n",
    "    #plot.set(xlabel=None, ylabel=None, xticklabels=[], yticklabels=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ba9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot Translucency ratings\")\n",
    "plot_hist(translucency_score, \"Trans\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16605f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Plot See-throughness ratings\")\n",
    "plot_hist(seethroughness_score, \"See-throughness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e39385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Plot Glow ratings\")\n",
    "plot_hist(glow_score, \"Glow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1417daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge all attributes\n",
    "all_attributes_wide, all_attribute_long = combine_attributes()\n",
    "\n",
    "all_attributes_wide[all_attributes_wide[\"ground_truth\"] == \"fake\"].sort_values(by=['translucency_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbf103",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributes_wide.to_csv(\"human_rating.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f32639",
   "metadata": {},
   "source": [
    "# Pair plot (Figure 2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f0ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(context='poster', font_scale=0.8)\n",
    "\n",
    "pair_plot_attribute = sns.pairplot(all_attributes_wide, hue = 'ground_truth', \n",
    "             diag_kind = 'hist', markers=[\"o\", \"o\"],\n",
    "             palette=real_fake_color_palette,\n",
    "             hue_order = real_fake_hue_order,\n",
    "             plot_kws = {'alpha': 0.8, 's': 100, 'edgecolor': 'k'},\n",
    "             diag_kws = {'alpha': 0.3, 'binwidth' : 0.2, 'multiple' : \"dodge\", 'kde':False},\n",
    "             #diag_kws = {'alpha': 0.3, 'binwidth' : 1, 'multiple' : \"dodge\", 'kde':False},\n",
    "             grid_kws=dict(diag_sharey=False),                      \n",
    "             height = 5, corner = True)\n",
    "sns.despine(offset=10, left=False, right = True)\n",
    "\n",
    "\n",
    "\n",
    "pair_plot_attribute = pair_plot_attribute.map_lower(corrfunc)\n",
    "pair_plot_attribute = pair_plot_attribute.set(xlim=(0, 1), ylim=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc81c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(data, feature1, feature2):\n",
    "    sns.set_context(context='poster', font_scale=0.8)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5, 5), dpi=100)\n",
    "    \n",
    "    plot = sns.scatterplot(data=data, x=feature1, y=feature2, hue=\"ground_truth\",\n",
    "                           alpha=0.7, hue_order=real_fake_hue_order, s=200,\n",
    "                           palette=real_fake_color_palette,\n",
    "                           legend=True)\n",
    "    plot.set(xlim=(0, 1), ylim=(0, 1))\n",
    "    #plot.set(xlabel=None, ylabel=None, xticklabels=[], yticklabels=[])\n",
    "    sns.despine(offset=10, left=False, right = True)\n",
    "    sns.move_legend(plot, \"upper left\", bbox_to_anchor=(1, 1), title='Groun truth')\n",
    "    \n",
    "    \n",
    "plot_scatter(all_attributes_wide, \"translucency_mean\", \"see_throughness_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be959b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(all_attributes_wide, \"translucency_mean\", \"glow_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6795dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(all_attributes_wide, \"see_throughness_mean\", \"glow_mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf79213",
   "metadata": {},
   "source": [
    "# Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16637f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_attributes_wide[all_attributes_wide[\"ground_truth\"] == \"fake\"].sort_values(by=['translucency_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267729bd",
   "metadata": {},
   "source": [
    "# Compare with SVM prediction (Figure 5B and Figure 5C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(context='poster', font_scale=0.5)\n",
    "file_path_svm_pred = \"data/svm_c001/svm_prediction_\"\n",
    "#file_path_svm_pred = \"data/svm_c0001/svm_prediction_\"\n",
    "\n",
    "r_table = plot_r_trend(file_path_svm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c4a1a",
   "metadata": {},
   "source": [
    "# Plot layer-wise SVM prediction with human perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_trend_long = r_table.melt('layer_name', var_name='attribute', value_name='correlation')\n",
    "\n",
    "\n",
    "xlabel = list(r_table[\"layer_name\"])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 7)\n",
    "\n",
    "sns.set_context(context='poster', font_scale=1)\n",
    "r_trend = sns.lineplot(\n",
    "                        data=r_trend_long,\n",
    "                        x=\"layer_name\", y=\"correlation\", hue=\"attribute\", style=\"attribute\",\n",
    "                        markers=True, dashes=True, alpha  = 0.9, markersize=20,\n",
    "                        palette=\"deep\", hue_order = [\"see-throughness\",\"glow\", \"translucent\"],\n",
    "    \n",
    "                    )\n",
    "\n",
    "ticks_val = range(18)\n",
    "tick_val_str = [str(i+1) for i in ticks_val]\n",
    "\n",
    "\n",
    "plt.xticks(ticks = ticks_val,labels = tick_val_str, rotation=90, fontsize=20)\n",
    "sns.move_legend(r_trend, \"upper left\", bbox_to_anchor=(1, 1), title='Attribute')\n",
    "sns.despine()\n",
    "r_trend.set(xlabel='Layer of W+ latent space', ylabel='Correlation',\n",
    "                           title='Correlation with human perception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_table[\"layer_name\"] = tick_val_str\n",
    "r_table[\"translucent\"] = np.round(r_table[\"translucent\"],3)\n",
    "r_table[\"see-throughness\"] = np.round(r_table[\"see-throughness\"],3)\n",
    "r_table[\"glow\"] = np.round(r_table[\"glow\"],3)\n",
    "\n",
    "#pd.options.display.float_format = '{:.3e}'.format\n",
    "\n",
    "# r_table = r_table.style.format({\n",
    "#    'tran-p': '{:.2e}'.format,\n",
    "#     'see-p': '{:.2e}'.format,\n",
    "#     'glow-p': '{:.2e}'.format,\n",
    "#     'translucent':'{:.2f}'.format,\n",
    "#     'see-throughness':'{:.2f}'.format,\n",
    "#     'glow':'{:.2f}'.format,\n",
    "# })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fda074",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new column based on complex conditions\n",
    "# create a list of our conditions\n",
    "def get_conditions(col_name):\n",
    "    #col_name = \"tran-p\"\n",
    "    conditions = [\n",
    "        (r_table[col_name] <= 0.0005),\n",
    "        (r_table[col_name] > 0.0005) & (r_table[col_name] <= 0.005),\n",
    "        (r_table[col_name] > 0.005) & (r_table[col_name] <= 0.001),\n",
    "        (r_table[col_name] > 0.001)\n",
    "        ]\n",
    "    return conditions\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "\n",
    "for col_name in [\"tran-p\", \"see-p\", \"glow-p\"]:\n",
    "    values = ['<0.0005', '<0.005', '<0.001', np.round(r_table[col_name],3)]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    p_val_name = col_name \n",
    "    r_table[p_val_name] = np.select(get_conditions(col_name), values)\n",
    "\n",
    "r_table = r_table.rename({\"tran-p\":\"translucent \",\n",
    "              \"see-p\":\"see-throughness \",\n",
    "              \"glow-p\": \"glow \", \n",
    "             }, axis=1)\n",
    "r_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f286f0",
   "metadata": {},
   "source": [
    "# Show layer-wise correlation with human perceptual rating (Supplementary Figure S6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 2)\n",
    "\n",
    "r_table2 = r_table.style.set_properties(**{'text-align': 'center',\n",
    "                                          'translucent':'{:,.2f}'.format,\n",
    "                                          'see-throughness':'{:,.2f}'.format,\n",
    "                                          'glow':'{:,.2f}'.format,\n",
    "                                          'background-color': 'white'})\n",
    "\n",
    "r_table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6395b",
   "metadata": {},
   "source": [
    "# Test correlation with tSNE and MDS features (Supplementary Figure S10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa948076",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(context='poster', font_scale=0.5)\n",
    "\n",
    "file_name = \"data/svm_dim_reduction/svm_prediction_tsne_5_norm.csv\"\n",
    "plot_svm_predict(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b0929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/svm_dim_reduction/svm_prediction_mds_norm.csv\"\n",
    "plot_svm_predict(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svm_predict(\"data/svm_c0001/svm_prediction_9.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
